"""
Contains composition of code for
    producer paradigm
        - generates the tf data Datasets

    provider paradigm
        - consumes the data generated by the datasets
        -

    Only use this class to interact with _Producer and _Provider

Author: Ian Q.

Notes:

"""
import tensorflow as tf
from Sequences.translation.Pipeline.producer import _Producer
from Sequences.translation.Pipeline.provider import _Provider

from Sequences.translation.Pipeline.config import LOAD_LOC, SAVE_LOC_RECORDS, \
    pattern, DATASET_DEFAULTS, logging_setup, SAVE_LOC_NPY
import pprint
import logging

class Dataset(object):
    def __init__(self, load_loc, save_loc, pattern, sess, use_raw=True):
        self.producer =  _Producer(save_loc, generate_raw=use_raw)
        self.provider = _Provider(load_location=save_loc, use_raw=use_raw)

        self.load_loc = load_loc
        self.glob_pattern = pattern
        self.logger = logging.getLogger(__name__)
        self.sess = sess

    def generate_records(self, load_loc=None, glob_pattern=None, overwrite=False):
        glob_pattern = self.glob_pattern if glob_pattern is None else glob_pattern
        load_loc = self.load_loc if load_loc is None else load_loc
        if self.producer is None:
            self.logger.error('use_raw was True, so Producer was not instantiated')
            raise Exception
        else:
            self.producer.generate_records(load_loc, glob_pattern, overwrite)


    def get_datasets(self, **kwargs):
        dataset_constructor_defaults = DATASET_DEFAULTS
        for k,v in kwargs.items():
            dataset_constructor_defaults[k] = v
        
        return_dict = self.provider.construct_datasets(dataset_constructor_defaults, )
        
        self.logger.info('Train Files: {}'.format(return_dict['train_files']))
        self.logger.info('Eval Files: {}'.format(return_dict['eval_files']))
        
        return return_dict['train_dataset'], return_dict['eval_dataset']
    
    
    def example(self, to_eval):
        self.logger.debug(self.sess.run(to_eval))
        

if __name__ == '__main__':
    logging_setup()

    use_raw = True
    sess = tf.InteractiveSession()
    init = tf.global_variables_initializer()

    ds = Dataset(LOAD_LOC, SAVE_LOC_NPY if use_raw else SAVE_LOC_RECORDS , pattern, sess, use_raw)

    # Producing
    ds.generate_records(overwrite=False)

    # Reading
    # _, to_eval = ds.get_datasets()
    # ds.example(to_eval)
    