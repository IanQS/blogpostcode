{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "- uses functions from [utils](https://github.com/IanQS/blogpostcode/blob/master/src/Tf_Exploration/exploration/utils.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "print(tf.__version__)\n",
    "\n",
    "#tf.enable_eager_execution()\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "import tqdm\n",
    "import sys\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Tf_Exploration.exploration.utils import FeatureProto, dataset_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['processed_data/tf_record_covtype_train_2019-01-06_01:00:00.tfrecord', 'processed_data/tf_record_covtype_test_2019-01-06_01:00:00.tfrecord']\n"
     ]
    }
   ],
   "source": [
    "filename_list = []\n",
    "for root, dirs, files in os.walk('processed_data/'):\n",
    "    for f in files:\n",
    "        if \"tfrecord\" in f:\n",
    "            filename_list.append(os.path.join(root, f))\n",
    "print(filename_list)\n",
    "dataset = tf.data.TFRecordDataset(filename_list)\n",
    "\n",
    "feature_proto = FeatureProto()\n",
    "num_cpus = os.cpu_count()\n",
    "features, labels = dataset_config(filenames=filename_list, batch_size=64, mapper=feature_proto.unpack, num_cpus=num_cpus,\n",
    "                                 repeat=True)\n",
    "columns = feature_proto.get_feature_columns()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_tensor = tf.feature_column.input_layer(features=features, feature_columns=columns)\n",
    "inputs = dense_tensor\n",
    "for units in [256, 16]:\n",
    "    dense_tensor = tf.layers.dense(dense_tensor, units, tf.nn.relu)\n",
    "logits = tf.layers.dense(dense_tensor, 8)\n",
    "\n",
    "# Verification\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(labels, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Training \n",
    "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=labels))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "train_op = optimizer.minimize(loss_op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Canned Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn_train(): # returns x, y (where y represents label's class index).\n",
    "    return dataset_config(filenames=filename_list, batch_size=64, mapper=feature_proto.unpack, num_cpus=num_cpus)\n",
    "\n",
    "def input_fn_eval(): # returns x, y (where y represents label's class index).\n",
    "    return dataset_config(filenames=filename_list, batch_size=2048, mapper=feature_proto.unpack, num_cpus=num_cpus)\n",
    "\n",
    "\n",
    "def evaluate(estimator):\n",
    "    # Fit model.\n",
    "    loss = estimator.evaluate(input_fn=input_fn_eval)\n",
    "    print(loss)\n",
    "    estimator.train(input_fn=input_fn_train)\n",
    "    loss = estimator.evaluate(input_fn=input_fn_eval)\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.0, 'average_loss': 698.097, 'loss': 1428178.6, 'global_step': 0}\n",
      "{'accuracy': 0.061537456, 'average_loss': 4.957756, 'loss': 10142.661, 'global_step': 9079}\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.estimator import DNNClassifier\n",
    "\n",
    "estimator = DNNClassifier(\n",
    "    feature_columns=columns,\n",
    "    n_classes=8,\n",
    "    hidden_units=[256, 16],\n",
    "    optimizer=lambda: tf.train.AdamOptimizer(\n",
    "        learning_rate=tf.train.exponential_decay(\n",
    "            learning_rate=0.1,\n",
    "            global_step=tf.train.get_global_step(),\n",
    "            decay_steps=1000,\n",
    "            decay_rate=0.96)\n",
    "    )\n",
    ")\n",
    "\n",
    "evaluate(estimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.0, 'average_loss': 2.0794415, 'loss': 4254.1567, 'global_step': 0}\n",
      "{'accuracy': 0.48759922, 'average_loss': 1.2731553, 'loss': 2604.6426, 'global_step': 9079}\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.estimator import BaselineClassifier\n",
    "\n",
    "classifier = BaselineClassifier(n_classes=8)\n",
    "\n",
    "evaluate(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
